# CSARST
CSARST Code
# A Channel and Spatial Attention Feature Extraction Method for Remote Sensing Image Super-Resolution Using Vision Transformer
The paper published on this topic is, [An Advanced Features Extraction Module for Remote Sensing Image Super-Resolution](https://ieeexplore.ieee.org/document/10595015) The main contribution of this work is from my Thesis work.

In recent years, convolutional neural networks (CNNs) have achieved remarkable advancement in the field of remote sensing image super-resolution due to the complexity and variability of textures and structures in remote sensing images (RSIs), which often repeat in the same images but differ across others. Current deep learning-based super-resolution models focus less on high-frequency features, which leads to suboptimal performance in capturing contours, textures, and spatial information. State-of-the-art CNN-based methods now focus on the feature extraction of RSIs using attention mechanisms. However, these methods are still incapable of effectively identifying and utilizing key content attention signals in RSIs. To solve this problem, we proposed an advanced feature extraction module called Channel and Spatial Attention Feature Extraction (CSA-FE) to effectively extract the features by using the channel and spatial attention incorporated with the standard vision transformer (ViT). The proposed method trained over the UCMerced dataset on scales 2, 3, and 4. The experimental results show that our proposed method helps the model focus on the specific channels and spatial locations containing high-frequency information so that the model can focus on relevant features and suppress irrelevant ones, which enhances the quality of super-resolved images. Our model achieved superior performance compared to various existing models.

![Model Diagram](https://github.com/user-attachments/assets/f73cedd8-167b-4a63-b89a-d546abe60ac1)


## Requirements
- Python 3.8+
- Pytorch>=1.8
- torchvision>=0.10.0
- einops
- matplotlib
- cv2
- scipy
- tqdm
- scikit
- torch-summary
- torchstat
- scikit-image

## Train
Download the UCMerced dataset [Google Drive](https://drive.google.com/file/d/12pmtffUEAhbEAIn_pit8FxwcdNk4Bgjg/view), they have been split into train/val/test data, where the original images would be taken as the HR references and the corresponding LR images are generated by bicubic down-sample.
```
# x4
python demo_train.py --model=CSARST --dataset=UCMerced --scale=4 --patch_size=192 
# x3
python demo_train.py --model=CSARST --dataset=UCMerced --scale=3 --patch_size=144
# x2
python demo_train.py --model=CSARST --dataset=UCMerced --scale=2 --patch_size=96
```
The train/val data paths are set in [data/init.py]()

## Test
The test data path and the save path can be edited in [demo_deploy.py]()
```
# x4
python demo_deploy.py --model=CSARST --scale=4
# x3
python demo_deploy.py --model=CSARST --scale=3
# x2
python demo_deploy.py --model=CSARST --scale=2
```
## Evaluation Metrics
Compute the evaluated results in terms of PSNR, SSIM, SCC, and SAM where the SR/HR paths can be edited in [calculate_PSNR_SSIM.py]()
```
cd metric_scripts 
python calculate_PSNR_SSIM.py
```
## Quantitative Results

![New](https://github.com/user-attachments/assets/40b1066a-fa65-4189-9eec-50d4921fbb1b)

## Perceptual Results
- Result on a scale factor of 3
![Screenshot_20](https://github.com/user-attachments/assets/7a1e6cf0-1a76-4492-8628-f4206c4b0b3f)
- Result on a scale factor of 4
![Screenshot_21](https://github.com/user-attachments/assets/e2dba69d-4f0d-40fe-a03e-c61cd25644cf)


## Citation
If you find this code useful for your research, please cite our paper:
```
@INPROCEEDINGS{10595015,
  author={Sultan, Naveed and Hajian, Amir and Aramvith, Supavadee},
  booktitle={2024 21st International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)}, 
  title={An Advanced Features Extraction Module for Remote Sensing Image Super-Resolution}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  keywords={Computational modeling;Superresolution;Feature extraction;Transformers;Decoding;Telecommunications;Spatial resolution;image super-resolution;remote sensing images;spatial attention;transformer},
  doi={10.1109/ECTI-CON60892.2024.10595015}}
```

## Acknowledgement
This code is built on [HSENet (Pytorch)](https://github.com/Shaosifan/HSENet) and [TRANSENet (Pytorch)](https://github.com/Shaosifan/TransENet). We thank the authors for sharing the codes.
